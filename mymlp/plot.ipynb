{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Structure.model import ThreeLayerNet\n",
    "from train import train\n",
    "from test import test\n",
    "from parameter_search import parameter_search\n",
    "from dataloaders import load_cifar10\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from Structure.model import ThreeLayerNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# current_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "# cifar10_dir = os.path.join(current_dir, 'cifar-10-batches-py')\n",
    "cifar10_dir = './cifar-10-batches-py'\n",
    "\n",
    "model_dir = './Model'\n",
    "\n",
    "X_train, y_train, X_test, y_test = load_cifar10(cifar10_dir)\n",
    "X_train = X_train.reshape(X_train.shape[0], -1)\n",
    "X_test = X_test.reshape(X_test.shape[0], -1)\n",
    "num_training = 49000\n",
    "num_validation = 1000\n",
    "mask = range(num_training, num_training + num_validation)\n",
    "X_val = X_train[mask]\n",
    "y_val = y_train[mask]\n",
    "mask = range(num_training)\n",
    "X_train = X_train[mask]\n",
    "y_train = y_train[mask]\n",
    "input_size = X_train.shape[1]\n",
    "output_size = 10\n",
    "model = ThreeLayerNet(input_size, 512,256, output_size,L2=0,actfunlist=['relu','leakyrelu'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.load2(r\"D:\\homework\\MLZL\\Model\\h1_512h2_256actfun_relu_leakyreluL2_0_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model,train_losses, val_losses, val_accuracies = train(model,X_train, y_train, X_val, y_val,learning_rate=1e-4,num_epochs=20)\n",
    "model.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load(model_dir)\n",
    "test_acc = test(model, X_test, y_test)\n",
    "print(\"Test accuracy:\", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_training(train_losses, val_losses, val_accuracies):\n",
    "    epochs = range(1, len(train_losses) + 1)\n",
    "\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    # 绘制训练集和验证集的 loss 曲线\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, train_losses, label='Training Loss')\n",
    "    plt.plot(epochs, val_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    # 绘制验证集的 accuracy 曲线\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, val_accuracies, label='Validation Accuracy', color='orange')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Validation Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_training(train_losses, val_losses, val_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight1=model.layers[0].weights\n",
    "weight2=model.layers[1].weights\n",
    "weight3=model.layers[2].weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "sns.heatmap(weight1, ax=axes[0], cmap='viridis')\n",
    "axes[0].set_title('Weight 1 Heatmap')\n",
    "sns.heatmap(weight2, ax=axes[1], cmap='viridis')\n",
    "axes[1].set_title('Weight 2 Heatmap')\n",
    "sns.heatmap(weight3, ax=axes[2], cmap='viridis')\n",
    "axes[2].set_title('Weight 3 Heatmap')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = parameter_search(X_train, y_train, X_val, y_val, X_test, y_test,actfunlist=['relu','leakyrelu'],epoch=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
